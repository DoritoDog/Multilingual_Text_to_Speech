{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multilingual Text-to-Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do when stuck\n",
    "- contact me\n",
    "- check https://github.com/Tomiinek/Multilingual_Text_to_Speech/issues?q=is%3Aissue+is%3Aclosed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import IPython\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q --user soundfile\n",
    "! pip install -q --user phonemizer\n",
    "! pip install -q --user epitran\n",
    "! pip install --user protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --user\n",
    "!pip install --user --upgrade librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Setup Dataset\n",
    "\n",
    "We download and extract these 2 datasets to data/comvoi and data/vctk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloads COMVOI - Dutch, German, French, Russian and Chinese audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!rm -rf data/comvoi\n",
    "!curl -O -L https://github.com/Tomiinek/Multilingual_Text_to_Speech/releases/download/v1.0/comvoi.zip\n",
    "!unzip -q comvoi.zip -d data/comvoi\n",
    "!rm comvoi.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloads VCTK - English audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!rm -rf data/vctk\n",
    "!curl -O -L http://studio336.sk/css/vctk.zip\n",
    "!mkdir data/vctk\n",
    "!unzip vctk.zip -d data/vctk\n",
    "!rm vctk.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove audio files in meta.csv files that do not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "base_dir = 'data/comvoi'\n",
    "for lang_dir in os.listdir(base_dir):\n",
    "    # Rename \"meta.csv\" files to \"_meta.csv\".\n",
    "    os.rename(os.path.join(base_dir, lang_dir, 'meta.csv'), os.path.join(base_dir, lang_dir, '_meta.csv'))\n",
    "    \n",
    "    with open(os.path.join(base_dir, lang_dir, '_meta.csv'), mode = 'r', encoding = 'utf-8') as meta_csv:\n",
    "        lines = meta_csv.readlines()\n",
    "        copy_of_lines = lines.copy()\n",
    "        \n",
    "        # Example line: 04|common_voice_fr_18576291.wav|Que suis-je auprès de Lui.\n",
    "        for line in lines:\n",
    "            audio_file_subdir = line.split('|')[0]\n",
    "            audio_file_name = line.split('|')[1]\n",
    "            \n",
    "            # Example audio_file_path: data/comvoi/fr/wavs/04/common_voice_fr_18576287.wav\n",
    "            audio_file_path = os.path.join(base_dir, lang_dir, 'wavs', audio_file_subdir, audio_file_name)\n",
    "            if not os.path.exists(audio_file_path):\n",
    "                copy_of_lines.remove(line)\n",
    "\n",
    "    with open(os.path.join(base_dir, lang_dir, 'meta.csv'), mode = 'w', encoding = 'utf-8') as meta_csv:\n",
    "        meta_csv.writelines(copy_of_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates a train.txt file that stores information for each dataset.\n",
    "### Also generates spectrograms for each audio file.\n",
    "\n",
    "To train the model, we need to:\n",
    "1. Create a linear spectrogram and mel spectrogram for every audio file. A spectrogram is a way to visualize an audio file.\n",
    "2. Create a file called train.txt.\n",
    "    - Every line in train.txt corresponds to an audio file\n",
    "    - It has this syntax: id|speaker|language|audio_file_path|mel_spectrogram_path|linear_spectrogram_path|text|phonemized_text\n",
    "    - Example: 002437|22-de|de|../comvoi_clean/de/wavs/22/common_voice_de_18706450.wav||../comvoi_clean/mel_spectrograms/002437.npy|../comvoi_clean/linear_spectrograms/002437.npy|Meine Sims haben immer Harndrang.|\n",
    "    - Phonemized text is left empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset.dataset as ds\n",
    "ds.TextToSpeechDataset.create_meta_file('my_common_voice', 'data/comvoi', 'train.txt', 22050, 1102, True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import dataset.dataset as ds\n",
    "ds.TextToSpeechDataset.create_meta_file('vctk', 'data/vctk/VCTK-Corpus/VCTK-Corpus', 'train.txt', 22050, 1102, True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to combine COMVOI and VCTK, so we combine the 2 train.txt files into a new one in data/comvoi_vctk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine COMVOI and VCTK train.txt files\n",
    "\n",
    "!mkdir data/comvoi_vctk\n",
    "!cat data/comvoi/train.txt data/vctk/VCTK-Corpus/VCTK-Corpus/train.txt > data/comvoi_vctk/train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure that file paths are relative to data/comvoi_vctk directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated train.txt file audio paths such as \"de/wavs/01/common_voice_de_18362579.wav\".<br>\n",
    "We need to access the audio from data/comvoi_vctk.<br>\n",
    "So change these audio paths to \"../comvoi/de/wavs/01/common_voice_de_18362579.wav\".<br>\n",
    "Similar process for VCTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back up the train.txt file first.\n",
    "!cp data/comvoi_vctk/train.txt data/comvoi_vctk/_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMVOI_LANGUAGES = ['de', 'fr', 'nl', 'ru', 'zh']\n",
    "VCTK_LANGUAGES = ['en-us']\n",
    "\n",
    "with open('data/comvoi_vctk/_train.txt', mode = 'r', encoding = 'utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        line_parts = line.split('|')\n",
    "        lang = line_parts[2]\n",
    "        if lang in COMVOI_LANGUAGES:\n",
    "            # Change e.g. \"de/wavs/01/common_voice_de_18362579.wav\" to \"../comvoi/de/wavs/01/common_voice_de_18362579.wav\"\n",
    "            line_parts[3] = os.path.join('../comvoi/', line_parts[3])\n",
    "            line_parts[4] = os.path.join('../comvoi/', line_parts[4])\n",
    "            line_parts[5] = os.path.join('../comvoi/', line_parts[5])\n",
    "            lines[i] = '|'.join(line_parts)\n",
    "        \n",
    "        if lang in VCTK_LANGUAGES:\n",
    "            line_parts[3] = os.path.join('../vctk/VCTK-Corpus/VCTK-Corpus/', line_parts[3])\n",
    "            line_parts[4] = os.path.join('../vctk/VCTK-Corpus/VCTK-Corpus/', line_parts[4])\n",
    "            line_parts[5] = os.path.join('../vctk/VCTK-Corpus/VCTK-Corpus/', line_parts[5])\n",
    "            lines[i] = '|'.join(line_parts)\n",
    "\n",
    "    with open('data/comvoi_vctk/train.txt', mode = 'w', encoding = 'utf-8') as file:\n",
    "        file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data/comvoi_vctk/_train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train.txt and val.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ML model needs train data and validation data (we do not need test data here).<br>\n",
    "https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7<br>\n",
    "So we remove some lines from train.txt and move them to a new val.txt file.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back up the train.txt file first.\n",
    "!cp data/comvoi_vctk/train.txt data/comvoi_vctk/_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open('data/comvoi_vctk/_train.txt', mode = 'r', encoding = 'utf-8') as file:\n",
    "    all_lines = file.readlines()\n",
    "    train, val = train_test_split(all_lines, test_size=0.15, random_state=42)\n",
    "    print(len(train))\n",
    "    print(len(val))\n",
    "        \n",
    "    with open('data/comvoi_vctk/train.txt', mode = 'w', encoding = 'utf-8') as file:\n",
    "        file.writelines(train)\n",
    "    with open('data/comvoi_vctk/val.txt', mode = 'w', encoding = 'utf-8') as file:\n",
    "        file.writelines(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data/comvoi_vctk/_train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generated_switching_comvoi_vctk.json is located in params/ and it contains information on how we will train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "!PYTHONIOENCODING=utf-8 python3 train.py --hyper_parameters generated_switching_comvoi_vctk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CH=INSERT_CHECKPOINT_FILE_NAME_HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/Multilingual_Text_to_Speech\n",
    "!rm logs.zip\n",
    "!zip logs.zip -r logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"fr|Cette requête s'explique par les relations peu conventionnelles que Schrödinger entretient avec les femmes.|01-zh|fr\"  | python3 synthesize.py --checkpoint checkpoints/$CH --save_spec\n",
    "!echo \"ru|Как считают современные археологи, на месте находились четыре различных храма.|01-zh|ru\"  | python3 synthesize.py --checkpoint checkpoints/$CH --save_spec\n",
    "!echo \"de|Sie liegt zwischen dem Ijsselmeer, der Ijssel und den Hügeln der Veluwe.|01-zh|de\"  | python3 synthesize.py --checkpoint checkpoints/$CH --save_spec\n",
    "!echo \"zh|wǒ zài nián qīng shí hou yě céng jīng zuò guò xǔ duō mèng.|01-zh|zh\"  | python3 synthesize.py --checkpoint checkpoints/$CH --save_spec\n",
    "!echo \"en|Now, the way I would do it is by better analysing the data.|01-zh|en-us\"  | python3 synthesize.py --checkpoint checkpoints/$CH --save_spec\n",
    "\n",
    "import IPython.display as ipd\n",
    "ipd.display(ipd.Audio('fr.wav'))\n",
    "ipd.display(ipd.Audio('ru.wav'))\n",
    "ipd.display(ipd.Audio('de.wav'))\n",
    "ipd.display(ipd.Audio('zh.wav'))\n",
    "ipd.display(ipd.Audio('en.wav'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
